# %% [markdown]
# # Segmenting and Clustering Neighborhoods in Toronto
# %% [markdown]
# First, it's needed to import pandas and BeautifulSoup to get the table from wikipedia:

# %%
import pandas as pd
import requests
from bs4 import BeautifulSoup
import json
from geopy.geocoders import Nominatim
import requests
from pandas.io.json import json_normalize
import matplotlib.cm as cm
import matplotlib.colors as colors
from sklearn.cluster import KMeans
import folium

# %%
req = requests.get("https://en.wikipedia.org/w/index.php?title=List_of_postal_codes_of_Canada:_M&oldid=945633050")

soup = BeautifulSoup(req.content,'lxml')

table = soup.find_all('table')[0]

df = pd.read_html(str(table))

nbh=pd.DataFrame(df[0])

# %%
nbh.head()

# %% [markdown]
# Let's see how many rows and columns exist in this table without processing it's data.

# %%
nbh.shape

# %% [markdown]
# Now i need to process the data, removing the rows that contains "Not assigned" in the Borough column and concatenating the neighborhoods from the same borough. 
# %% [markdown]
# First, let's remove the "Not Assigned" rows.

# %%
nbh.set_index('Borough', inplace=True) 
nbh.drop('Not assigned', axis=0, inplace=True)
nbh.reset_index(inplace=True)
nbh.head()


# %%
nbh = nbh[['Postcode','Borough','Neighbourhood']]
nbh.sort_values(by='Postcode', inplace=True)
nbh.head()

# %%
nbh.shape

# %% [markdown]
# Now, let's concatenate the neighborhoods from the same Borough.

# %%
nbh2=nbh.groupby(['Postcode','Borough']).apply(lambda x: ','.join(x['Neighbourhood']))
nbh2 = nbh2.reset_index()
nbh2.columns = ['Postcode','Borough','Neighbourhood']
nbh2.head(10)


# %%
nbh2.shape